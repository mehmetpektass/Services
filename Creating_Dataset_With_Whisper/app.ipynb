{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c884e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "785e1941",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = Path(\".\") / \".env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f1a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe audio file using OpenAI Whisper API with timestamp data\n",
    "\n",
    "\n",
    "def transcribe_with_timestamps(audio_file_path, model=\"whisper-1\"):\n",
    "    print(f\"Starting transcription for: {audio_file_path}\")\n",
    "\n",
    "    try:\n",
    "        with open(audio_file_path, \"rb\") as audio_file:\n",
    "            transcript = client.audio.transcriptions.create(\n",
    "                model=model,\n",
    "                file=audio_file,\n",
    "                response_format=\"verbose_json\",\n",
    "                timestamp_granularities=[\"segment\"],\n",
    "            )\n",
    "        print(f\"Transcription completed. Found {len(transcript.segments)} segments\")\n",
    "        return transcript\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during transcription: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1abc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio file into segments based on timestamp data\n",
    "\n",
    "\n",
    "def split_audio_by_segments(audio_file_path, segments, output_dir=\"output_segments\"):\n",
    "    print(f\"Loading audio file: {audio_file_path}\")\n",
    "\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "    segments_data = []\n",
    "\n",
    "    print(f\"Splitting audio into {len(segments)} segments...\")\n",
    "\n",
    "    for i, segment in enumerate(segments):\n",
    "        # Convert seconds to milliseconds for pydub\n",
    "        start_ms = int(segment.start * 1000)\n",
    "        end_ms = int(segment.end * 1000)\n",
    "\n",
    "        # Extract segment\n",
    "        segment_audio = audio[start_ms:end_ms]\n",
    "\n",
    "        filename = f\"segment_{i+1:03d}.wav\"\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        segment_audio.export(output_path, format=\"wav\")\n",
    "\n",
    "        # Store segment data with relative path for portability\n",
    "        segment_data = {\n",
    "            \"id\": i + 1,\n",
    "            \"filename\": filename,\n",
    "            \"start\": segment.start,\n",
    "            \"end\": segment.end,\n",
    "            \"duration\": segment.end - segment.start,\n",
    "            \"text\": segment.text.strip(),\n",
    "            \"file_path\": filename,  # Use relative path within the output directory\n",
    "        }\n",
    "\n",
    "        segments_data.append(segment_data)\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"Processed {i + 1}/{len(segments)} segments\")\n",
    "\n",
    "    print(f\"Audio splitting completed. All segments saved to: {output_dir}\")\n",
    "    return segments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21948ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset to CSV file in the same directory as audio segments\n",
    "\n",
    "\n",
    "def save_dataset(segments_data, output_dir=\"output_segments\"):\n",
    "    csv_file_path = os.path.join(output_dir, \"dataset.csv\")\n",
    "    print(f\"Saving dataset to: {csv_file_path}\")\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(segments_data)\n",
    "\n",
    "    # Save to CSV\n",
    "    df.to_csv(csv_file_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"Dataset saved successfully with {len(segments_data)} entries\")\n",
    "    print(f\"CSV file location: {csv_file_path}\")\n",
    "\n",
    "    return csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd936a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_large_audio_file(audio_file_path, chunk_duration_minutes=3):  # === FIXED: Reduced to 3 minutes ===\n",
    "    \"\"\"\n",
    "    Process large audio files by splitting them into chunks first\n",
    "    \"\"\"\n",
    "    print(f\"Processing large audio file: {audio_file_path}\")\n",
    "\n",
    "    # Load audio\n",
    "    audio = AudioSegment.from_file(audio_file_path)\n",
    "    duration_minutes = len(audio) / (1000 * 60)\n",
    "\n",
    "    print(f\"Audio duration: {duration_minutes:.2f} minutes\")\n",
    "\n",
    "    if duration_minutes <= chunk_duration_minutes:\n",
    "        print(\"File is small enough, processing directly...\")\n",
    "        return process_audio_file(audio_file_path)\n",
    "\n",
    "    # === FIXED: More aggressive chunk size calculation ===\n",
    "    file_size_mb = os.path.getsize(audio_file_path) / (1024 * 1024)\n",
    "\n",
    "    # Calculate chunks needed to keep each under 20MB when converted to audio format\n",
    "    estimated_audio_size_per_minute = file_size_mb / duration_minutes * 5  # WAV is ~5x larger than MP4\n",
    "    target_chunk_minutes = min(15 / estimated_audio_size_per_minute, chunk_duration_minutes)  # Target 15MB chunks\n",
    "    target_chunk_minutes = max(1, target_chunk_minutes)  # Minimum 1 minute\n",
    "\n",
    "    print(f\"Estimated audio size per minute: {estimated_audio_size_per_minute:.1f} MB\")\n",
    "    print(f\"Target chunk duration: {target_chunk_minutes:.1f} minutes\")\n",
    "\n",
    "    # Split into chunks\n",
    "    chunk_duration_ms = int(target_chunk_minutes * 60 * 1000)\n",
    "    chunks = []\n",
    "\n",
    "    print(f\"Splitting into {target_chunk_minutes:.1f}-minute chunks...\")\n",
    "\n",
    "    chunk_count = 0\n",
    "    for i in range(0, len(audio), chunk_duration_ms):\n",
    "        chunk = audio[i:i + chunk_duration_ms]\n",
    "        chunk_count += 1\n",
    "\n",
    "        # === FIXED: Use MP3 format instead of WAV to reduce file size ===\n",
    "        chunk_filename = f\"temp_chunk_{chunk_count}.mp3\"\n",
    "\n",
    "        # === FIXED: Export with lower bitrate to ensure small file size ===\n",
    "        chunk.export(\n",
    "            chunk_filename,\n",
    "            format=\"mp3\",\n",
    "            parameters=[\"-ar\", \"16000\", \"-ac\", \"1\", \"-b:a\", \"64k\"]  # 16kHz mono 64kbps\n",
    "        )\n",
    "\n",
    "        # Check chunk file size\n",
    "        chunk_size_mb = os.path.getsize(chunk_filename) / (1024 * 1024)\n",
    "        print(f\"Created {chunk_filename} - Size: {chunk_size_mb:.1f} MB\")\n",
    "\n",
    "        # === FIXED: If chunk is still too big, split it further ===\n",
    "        if chunk_size_mb > 20:\n",
    "            print(f\"Chunk {chunk_filename} is too large ({chunk_size_mb:.1f} MB), splitting further...\")\n",
    "            os.remove(chunk_filename)  # Remove the large chunk\n",
    "\n",
    "            # Split this chunk into smaller pieces\n",
    "            sub_chunk_duration = chunk_duration_ms // 2\n",
    "            for j in range(0, len(chunk), sub_chunk_duration):\n",
    "                sub_chunk = chunk[j:j + sub_chunk_duration]\n",
    "                sub_chunk_filename = f\"temp_chunk_{chunk_count}_{j//sub_chunk_duration + 1}.mp3\"\n",
    "\n",
    "                sub_chunk.export(\n",
    "                    sub_chunk_filename,\n",
    "                    format=\"mp3\",\n",
    "                    parameters=[\"-ar\", \"16000\", \"-ac\", \"1\", \"-b:a\", \"64k\"]\n",
    "                )\n",
    "\n",
    "                sub_chunk_size = os.path.getsize(sub_chunk_filename) / (1024 * 1024)\n",
    "                print(f\"Created sub-chunk {sub_chunk_filename} - Size: {sub_chunk_size:.1f} MB\")\n",
    "\n",
    "                chunks.append({\n",
    "                    'filename': sub_chunk_filename,\n",
    "                    'start_offset': (i + j) / 1000\n",
    "                })\n",
    "        else:\n",
    "            chunks.append({\n",
    "                'filename': chunk_filename,\n",
    "                'start_offset': i / 1000  # in seconds\n",
    "            })\n",
    "\n",
    "    print(f\"Created {len(chunks)} chunks\")\n",
    "\n",
    "    all_segments_data = []\n",
    "\n",
    "    # Process each chunk\n",
    "    for idx, chunk_info in enumerate(chunks):\n",
    "        print(f\"Processing chunk {idx + 1}/{len(chunks)}: {chunk_info['filename']}\")\n",
    "\n",
    "        # === FIXED: Check file size before sending to API ===\n",
    "        chunk_size_mb = os.path.getsize(chunk_info['filename']) / (1024 * 1024)\n",
    "        if chunk_size_mb > 25:\n",
    "            print(f\"Skipping {chunk_info['filename']} - still too large ({chunk_size_mb:.1f} MB)\")\n",
    "            continue\n",
    "\n",
    "        # Transcribe chunk\n",
    "        transcript = transcribe_with_timestamps(chunk_info['filename'])\n",
    "\n",
    "        if transcript and transcript.segments:\n",
    "            # Adjust timestamps based on chunk offset\n",
    "            for segment in transcript.segments:\n",
    "                segment.start += chunk_info['start_offset']\n",
    "                segment.end += chunk_info['start_offset']\n",
    "\n",
    "            # Split audio for this chunk - use the chunk file, not the original\n",
    "            chunk_output_dir = f\"1.audio_output_segments_chunk_{idx + 1}\"\n",
    "\n",
    "            # Adjust segments back to chunk-relative timestamps for splitting\n",
    "            chunk_segments = []\n",
    "            for segment in transcript.segments:\n",
    "                # Create a copy of segment with chunk-relative timestamps\n",
    "                chunk_segment = type('obj', (object,), {\n",
    "                    'start': segment.start - chunk_info['start_offset'],  # Convert to chunk-relative\n",
    "                    'end': segment.end - chunk_info['start_offset'],     # Convert to chunk-relative\n",
    "                    'text': segment.text\n",
    "                })\n",
    "                chunk_segments.append(chunk_segment)\n",
    "\n",
    "            segments_data = split_audio_by_segments(\n",
    "                chunk_info['filename'],  # Use chunk file instead of original audio_file_path\n",
    "                chunk_segments,          # Use chunk-relative timestamps\n",
    "                chunk_output_dir\n",
    "            )\n",
    "\n",
    "            # Now update segments_data with absolute timestamps and file paths\n",
    "            for j, segment in enumerate(segments_data):\n",
    "                segment['start'] = transcript.segments[j].start      # Use absolute timestamp\n",
    "                segment['end'] = transcript.segments[j].end          # Use absolute timestamp\n",
    "                segment['duration'] = segment['end'] - segment['start']  # Recalculate duration\n",
    "                segment['file_path'] = segment['filename']\n",
    "\n",
    "            all_segments_data.extend(segments_data)\n",
    "\n",
    "        # Clean up temporary chunk file\n",
    "        if os.path.exists(chunk_info['filename']):\n",
    "            os.remove(chunk_info['filename'])\n",
    "\n",
    "        # Add delay to respect API rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    print(f\"Large file processing completed. Total segments: {len(all_segments_data)}\")\n",
    "\n",
    "    # Move all segments to a single output directory and save dataset\n",
    "    final_output_dir = \"output_segments\"\n",
    "    Path(final_output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "    print(\"Consolidating all segments into single directory...\")\n",
    "\n",
    "    # Move files and update paths\n",
    "    for i, segment in enumerate(all_segments_data):\n",
    "        # Find the source file\n",
    "        source_file = None\n",
    "        for chunk_idx in range(len(chunks)):\n",
    "            chunk_dir = f\"1.audio_output_segments_chunk_{chunk_idx + 1}\"\n",
    "            potential_path = os.path.join(chunk_dir, segment['filename'])\n",
    "            if os.path.exists(potential_path):\n",
    "                source_file = potential_path\n",
    "                break\n",
    "\n",
    "        if source_file:\n",
    "            # Create new filename to avoid conflicts\n",
    "            new_filename = f\"segment_{i+1:03d}.wav\"\n",
    "            new_path = os.path.join(final_output_dir, new_filename)\n",
    "\n",
    "            # Move file\n",
    "            os.rename(source_file, new_path)\n",
    "\n",
    "            # Update segment data\n",
    "            segment['filename'] = new_filename\n",
    "            segment['file_path'] = new_filename\n",
    "\n",
    "    # Clean up chunk directories\n",
    "    for chunk_idx in range(len(chunks)):\n",
    "        chunk_dir = f\"1.audio_output_segments_chunk_{chunk_idx + 1}\"\n",
    "        if os.path.exists(chunk_dir):\n",
    "            try:\n",
    "                os.rmdir(chunk_dir)\n",
    "            except:\n",
    "                pass  # Directory might not be empty, that's ok\n",
    "\n",
    "    # Save consolidated dataset\n",
    "    save_dataset(all_segments_data, final_output_dir)\n",
    "\n",
    "    return all_segments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fe42d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function to process a single audio file\n",
    "\n",
    "def process_audio_file(audio_file_path):\n",
    "    print(f\"Starting audio processing pipeline for: {audio_file_path}\")\n",
    "\n",
    "    transcript = transcribe_with_timestamps(audio_file_path)\n",
    "\n",
    "    if not transcript or not transcript.segments:\n",
    "        print(\"Transcription failed or no segments found\")\n",
    "        return None\n",
    "\n",
    "    segments_data = split_audio_by_segments(audio_file_path, transcript.segments)\n",
    "\n",
    "    save_dataset(segments_data, \"output_segments\")\n",
    "\n",
    "    return segments_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b35346",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configuration\n",
    "    AUDIO_FILE_PATH = \"{You need to add here the path of your file}\"\n",
    "\n",
    "    # Check if file exists\n",
    "    if not os.path.exists(AUDIO_FILE_PATH):\n",
    "        print(f\"Audio file not found: {AUDIO_FILE_PATH}\")\n",
    "        print(\"Please update AUDIO_FILE_PATH with your actual audio file path\")\n",
    "    else:\n",
    "        # Get file size to determine processing method\n",
    "        file_size_mb = os.path.getsize(AUDIO_FILE_PATH) / (1024 * 1024)\n",
    "        print(f\"Audio file size: {file_size_mb:.2f} MB\")\n",
    "\n",
    "        if file_size_mb > 25:  # OpenAI has 25MB limit\n",
    "            print(\"File is larger than 25MB, using chunked processing...\")\n",
    "            segments_data = process_large_audio_file(AUDIO_FILE_PATH)\n",
    "        else:\n",
    "            print(\"File size is acceptable, processing directly...\")\n",
    "            segments_data = process_audio_file(AUDIO_FILE_PATH)\n",
    "\n",
    "        if segments_data:\n",
    "            print(f\"Processing completed successfully!\")\n",
    "            print(f\"Total segments created: {len(segments_data)}\")\n",
    "            print(f\"Check 'output_segments' directory for audio files and dataset.csv\")\n",
    "\n",
    "            # Show CSV file location\n",
    "            csv_path = os.path.join(\"output_segments\", \"dataset.csv\")\n",
    "            if os.path.exists(csv_path):\n",
    "                print(f\"Dataset CSV file: {csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Whisper Dataset Project",
   "language": "python",
   "name": "whisper-dataset"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
